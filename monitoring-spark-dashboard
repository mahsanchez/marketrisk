https://github.com/LucaCanali/Miscellaneous/tree/master/Spark_Dashboard


Install influxdb1

wget https://dl.influxdata.com/influxdb/releases/influxdb_1.8.10_amd64.deb
sudo dpkg -i influxdb_1.8.10_amd64.deb


Enable 
sudo vi /etc/influxdb/influxdb.conf

[[graphite]]
  enabled = true
  bind-address = ":2003"
  database = "graphite"
  retention-policy = ""
  protocol = "tcp"
  batch-size = 5000
  batch-pending = 10
  batch-timeout = "1s"
  consistency-level = "one"
  separator = "."
  udp-read-buffer = 0
  templates = [
    # JVM source
    "*.*.jvm.pools.* username.applicationid.process.namespace.namespace.measurement*",
    # YARN source
    "*.*.applicationMaster.* username.applicationid.namespace.measurement*",
    # shuffle service source
    "*.shuffleService.* username.namespace.measurement*",
    # streaming
    "*.*.*.spark.streaming.* username.applicationid.process.namespace.namespace.id.measurement*",
    # generic template for driver and executor sources
    "username.applicationid.process.namespace.measurement*" ]
    
    Spark Metrics Properties
    
    *.sink.graphite.class=org.apache.spark.metrics.sink.GraphiteSink
*.sink.graphite.host=<graphiteEndPoint_influxDB_hostName>
*.sink.graphite.port=<listening_port> # must match influxDB configuration file
*.sink.graphite.period=10   # Configurable
*.sink.graphite.unit=seconds
*.sink.graphite.prefix=lucatest # Optional value/label
*.source.jvm.class=org.apache.spark.metrics.source.JvmSource # Optional JVM metrics
    
Grafana (listen on port 3000)
https://grafana.com/ 

sudo apt-get install -y adduser libfontconfig1
wget https://dl.grafana.com/enterprise/release/grafana-enterprise_9.3.2_amd64.deb
sudo dpkg -i grafana-enterprise_9.3.2_amd64.deb

sudo /bin/systemctl start grafana-server
systemctl start grafana-server.service

netstat -an| grep 3000

Grafana - Create a data source to connect to InfluxDB.

    Set the http URL with the correct port number, default: http://bluefish:8086
    Set the InfluxDB database name: default is graphite (no password)

Add Your DataSource to InfluxDB


export SPARK_HOME=/home/bluefish/dscience/spark-3.3.1-bin-hadoop3

$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://bluefish:7077  --driver-memory 512m --executor-memory 512m --executor-cores 4 $SPARK_HOME/examples/jars/spark-examples_2.12-3.3.1.jar  10000

